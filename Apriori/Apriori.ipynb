{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. Carregamento e Pré-processamento\n",
        "def load_and_preprocess_data(url):\n",
        "    \"\"\"Carrega e pré-processa os dados\"\"\"\n",
        "    print(\"Carregando e pré-processando dados...\")\n",
        "\n",
        "    # Carregar dados\n",
        "    import requests\n",
        "    import zipfile\n",
        "    import io\n",
        "\n",
        "    response = requests.get(url)\n",
        "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "        with z.open('online_retail_dataset.csv') as f:\n",
        "            df = pd.read_csv(f)\n",
        "\n",
        "    # Pré-processamento básico\n",
        "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "    df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]  # Remove cancelamentos\n",
        "    df = df[df['Quantity'] > 0]  # Remove quantidades negativas\n",
        "    df = df[df['UnitPrice'] > 0]  # Remove preços zero ou negativos\n",
        "\n",
        "    # Remover outliers\n",
        "    df = df[df['Quantity'] <= df['Quantity'].quantile(0.95)]\n",
        "    df = df[df['UnitPrice'] <= df['UnitPrice'].quantile(0.95)]\n",
        "\n",
        "    # Normalizar descrições\n",
        "    df['Description'] = df['Description'].str.strip().str.upper()\n",
        "\n",
        "    # Adicionar informação temporal\n",
        "    df['Month'] = df['InvoiceDate'].dt.month\n",
        "    df['WeekDay'] = df['InvoiceDate'].dt.dayofweek\n",
        "\n",
        "    return df\n",
        "\n",
        "# 2. Criar transações válidas\n",
        "def create_valid_transactions(df):\n",
        "    \"\"\"Cria transações válidas a partir do DataFrame\"\"\"\n",
        "    print(\"Criando transações válidas...\")\n",
        "\n",
        "    # Calcular tamanho das transações\n",
        "    transaction_sizes = df.groupby('InvoiceNo').size()\n",
        "\n",
        "    # Filtrar transações válidas (entre 2 e 95º percentil)\n",
        "    valid_size = transaction_sizes[\n",
        "        (transaction_sizes >= 2) &\n",
        "        (transaction_sizes <= transaction_sizes.quantile(0.95))\n",
        "    ].index\n",
        "\n",
        "    # Criar lista de transações\n",
        "    transactions = df[df['InvoiceNo'].isin(valid_size)].groupby('InvoiceNo')['Description'].agg(list)\n",
        "\n",
        "    return transactions.tolist()\n",
        "\n",
        "# 3. Gerar regras com validação temporal\n",
        "def generate_rules_by_period(df, min_support=0.05, min_confidence=0.7, max_lift=20):\n",
        "    \"\"\"Gera regras por período\"\"\"\n",
        "    print(\"Gerando regras por período...\")\n",
        "\n",
        "    rules_by_month = {}\n",
        "\n",
        "    for month in df['Month'].unique():\n",
        "        # Filtrar dados do mês\n",
        "        month_data = df[df['Month'] == month]\n",
        "\n",
        "        # Criar transações do mês\n",
        "        month_transactions = create_valid_transactions(month_data)\n",
        "\n",
        "        # Codificar transações\n",
        "        te = TransactionEncoder()\n",
        "        te_ary = te.fit(month_transactions).transform(month_transactions)\n",
        "        df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "        # Gerar itemsets frequentes\n",
        "        frequent_itemsets = apriori(df_encoded,\n",
        "                                  min_support=min_support,\n",
        "                                  use_colnames=True)\n",
        "\n",
        "        if len(frequent_itemsets) > 0:\n",
        "            # Gerar regras\n",
        "            rules = association_rules(frequent_itemsets,\n",
        "                                    metric=\"confidence\",\n",
        "                                    min_threshold=min_confidence)\n",
        "\n",
        "            # Filtrar por lift\n",
        "            rules = rules[rules['lift'] <= max_lift]\n",
        "\n",
        "            rules_by_month[month] = rules\n",
        "            print(f\"Mês {month}: {len(rules)} regras encontradas\")\n",
        "\n",
        "    return rules_by_month\n",
        "\n",
        "# 4. Validar regras\n",
        "def validate_rules(rules_by_month, min_periods=2):\n",
        "    \"\"\"Valida regras entre períodos\"\"\"\n",
        "    print(\"Validando regras...\")\n",
        "\n",
        "    all_rules = []\n",
        "\n",
        "    # Combinar regras de todos os períodos\n",
        "    for month, rules in rules_by_month.items():\n",
        "        if len(rules) > 0:\n",
        "            rules['month'] = month\n",
        "            all_rules.append(rules)\n",
        "\n",
        "    if len(all_rules) > 0:\n",
        "        combined_rules = pd.concat(all_rules)\n",
        "\n",
        "        # Contar ocorrências de cada regra\n",
        "        rule_counts = combined_rules.groupby(['antecedents', 'consequents']).size()\n",
        "\n",
        "        # Filtrar regras que aparecem em múltiplos períodos\n",
        "        consistent_rules = rule_counts[rule_counts >= min_periods].index\n",
        "\n",
        "        # Filtrar regras consistentes\n",
        "        validated_rules = combined_rules[\n",
        "            combined_rules.set_index(['antecedents', 'consequents']).index.isin(consistent_rules)\n",
        "        ]\n",
        "\n",
        "        return validated_rules\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# 5. Analisar e apresentar resultados\n",
        "def analyze_results(rules, df):\n",
        "    \"\"\"Analisa e apresenta os resultados\"\"\"\n",
        "    print(\"\\n=== Análise das Regras ===\")\n",
        "\n",
        "    # Top regras por diferentes métricas\n",
        "    print(\"\\nTop 5 Regras por Confiança:\")\n",
        "    print(rules.nlargest(5, 'confidence')[\n",
        "        ['antecedents', 'consequents', 'confidence', 'lift', 'support']\n",
        "    ])\n",
        "\n",
        "    print(\"\\nTop 5 Regras por Lift (realista):\")\n",
        "    print(rules.nlargest(5, 'lift')[\n",
        "        ['antecedents', 'consequents', 'confidence', 'lift', 'support']\n",
        "    ])\n",
        "\n",
        "    # Estatísticas das métricas\n",
        "    print(\"\\nEstatísticas das Métricas:\")\n",
        "    metrics_stats = rules[['support', 'confidence', 'lift']].describe()\n",
        "    print(metrics_stats)\n",
        "\n",
        "    # Análise de valor\n",
        "    print(\"\\nAnálise de Valor das Regras:\")\n",
        "    df_value = df.copy()\n",
        "    df_value['TotalValue'] = df_value['Quantity'] * df_value['UnitPrice']\n",
        "\n",
        "    value_by_product = df_value.groupby('Description')['TotalValue'].sum()\n",
        "\n",
        "    for _, rule in rules.nlargest(5, 'lift').iterrows():\n",
        "        ant_products = list(rule['antecedents'])\n",
        "        cons_products = list(rule['consequents'])\n",
        "\n",
        "        ant_value = sum(value_by_product[ant_products])\n",
        "        cons_value = sum(value_by_product[cons_products])\n",
        "\n",
        "        print(f\"\\nRegra: {ant_products} -> {cons_products}\")\n",
        "        print(f\"Valor Total Antecedentes: £{ant_value:.2f}\")\n",
        "        print(f\"Valor Total Consequentes: £{cons_value:.2f}\")\n",
        "\n",
        "# 6. Função principal\n",
        "def main():\n",
        "    # Parâmetros\n",
        "    MIN_SUPPORT = 0.05    # 5% de suporte mínimo\n",
        "    MIN_CONFIDENCE = 0.7  # 70% de confiança mínima\n",
        "    MAX_LIFT = 20        # Limite máximo de lift\n",
        "    MIN_PERIODS = 2      # Número mínimo de períodos para validação\n",
        "\n",
        "    # URL do dataset\n",
        "    url = \"https://raw.githubusercontent.com/klaytoncastro/idp-machinelearning/main/resources/online_retail.zip\"\n",
        "\n",
        "    # 1. Carregar e pré-processar dados\n",
        "    df = load_and_preprocess_data(url)\n",
        "\n",
        "    # 2. Gerar regras por período\n",
        "    rules_by_month = generate_rules_by_period(df, MIN_SUPPORT, MIN_CONFIDENCE, MAX_LIFT)\n",
        "\n",
        "    # 3. Validar regras\n",
        "    validated_rules = validate_rules(rules_by_month, MIN_PERIODS)\n",
        "\n",
        "    # 4. Analisar resultados\n",
        "    if len(validated_rules) > 0:\n",
        "        analyze_results(validated_rules, df)\n",
        "\n",
        "        # Salvar resultados\n",
        "        validated_rules.to_csv('regras_validadas.csv', index=False)\n",
        "        print(\"\\nResultados salvos em 'regras_validadas.csv'\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma regra válida encontrada com os parâmetros atuais.\")\n",
        "        print(\"Tente ajustar os parâmetros (diminuir suporte ou confiança)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIIcCK0BPBWn",
        "outputId": "c35495be-9893-4005-de35-ebebcce7d256"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando e pré-processando dados...\n",
            "Gerando regras por período...\n",
            "Criando transações válidas...\n",
            "Mês 12: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 1: 2 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 2: 4 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 3: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 4: 4 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 5: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 6: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 7: 1 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 8: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 9: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 10: 0 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 11: 0 regras encontradas\n",
            "Validando regras...\n",
            "\n",
            "=== Análise das Regras ===\n",
            "\n",
            "Top 5 Regras por Confiança:\n",
            "                         antecedents                        consequents  \\\n",
            "1  (GREEN REGENCY TEACUP AND SAUCER)  (ROSES REGENCY TEACUP AND SAUCER)   \n",
            "0  (ROSES REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
            "2  (ROSES REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
            "3  (GREEN REGENCY TEACUP AND SAUCER)  (ROSES REGENCY TEACUP AND SAUCER)   \n",
            "\n",
            "   confidence       lift   support  \n",
            "1    0.812500  11.746429  0.051383  \n",
            "0    0.742857  11.746429  0.051383  \n",
            "2    0.737705  10.884171  0.050000  \n",
            "3    0.737705  10.884171  0.050000  \n",
            "\n",
            "Top 5 Regras por Lift (realista):\n",
            "                         antecedents                        consequents  \\\n",
            "0  (ROSES REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
            "1  (GREEN REGENCY TEACUP AND SAUCER)  (ROSES REGENCY TEACUP AND SAUCER)   \n",
            "2  (ROSES REGENCY TEACUP AND SAUCER)  (GREEN REGENCY TEACUP AND SAUCER)   \n",
            "3  (GREEN REGENCY TEACUP AND SAUCER)  (ROSES REGENCY TEACUP AND SAUCER)   \n",
            "\n",
            "   confidence       lift   support  \n",
            "0    0.742857  11.746429  0.051383  \n",
            "1    0.812500  11.746429  0.051383  \n",
            "2    0.737705  10.884171  0.050000  \n",
            "3    0.737705  10.884171  0.050000  \n",
            "\n",
            "Estatísticas das Métricas:\n",
            "        support  confidence       lift\n",
            "count  4.000000    4.000000   4.000000\n",
            "mean   0.050692    0.757692  11.315300\n",
            "std    0.000799    0.036619   0.497825\n",
            "min    0.050000    0.737705  10.884171\n",
            "25%    0.050000    0.737705  10.884171\n",
            "50%    0.050692    0.740281  11.315300\n",
            "75%    0.051383    0.760268  11.746429\n",
            "max    0.051383    0.812500  11.746429\n",
            "\n",
            "Análise de Valor das Regras:\n",
            "\n",
            "Regra: ['ROSES REGENCY TEACUP AND SAUCER'] -> ['GREEN REGENCY TEACUP AND SAUCER']\n",
            "Valor Total Antecedentes: £20629.27\n",
            "Valor Total Consequentes: £19047.20\n",
            "\n",
            "Regra: ['GREEN REGENCY TEACUP AND SAUCER'] -> ['ROSES REGENCY TEACUP AND SAUCER']\n",
            "Valor Total Antecedentes: £19047.20\n",
            "Valor Total Consequentes: £20629.27\n",
            "\n",
            "Regra: ['ROSES REGENCY TEACUP AND SAUCER'] -> ['GREEN REGENCY TEACUP AND SAUCER']\n",
            "Valor Total Antecedentes: £20629.27\n",
            "Valor Total Consequentes: £19047.20\n",
            "\n",
            "Regra: ['GREEN REGENCY TEACUP AND SAUCER'] -> ['ROSES REGENCY TEACUP AND SAUCER']\n",
            "Valor Total Antecedentes: £19047.20\n",
            "Valor Total Consequentes: £20629.27\n",
            "\n",
            "Resultados salvos em 'regras_validadas.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load_and_preprocess_data(url):\n",
        "    \"\"\"Carrega e pré-processa os dados\"\"\"\n",
        "    print(\"Carregando e pré-processando dados...\")\n",
        "\n",
        "    import requests\n",
        "    import zipfile\n",
        "    import io\n",
        "\n",
        "    response = requests.get(url)\n",
        "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "        with z.open('online_retail_dataset.csv') as f:\n",
        "            df = pd.read_csv(f)\n",
        "\n",
        "    # Pré-processamento básico\n",
        "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "    df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "    df = df[df['Quantity'] > 0]\n",
        "    df = df[df['UnitPrice'] > 0]\n",
        "\n",
        "    # Ajuste mais suave para outliers (97.5º percentil em vez de 95º)\n",
        "    df = df[df['Quantity'] <= df['Quantity'].quantile(0.975)]\n",
        "    df = df[df['UnitPrice'] <= df['UnitPrice'].quantile(0.975)]\n",
        "\n",
        "    # Normalizar descrições\n",
        "    df['Description'] = df['Description'].str.strip().str.upper()\n",
        "\n",
        "    # Adicionar informação temporal\n",
        "    df['Month'] = df['InvoiceDate'].dt.month\n",
        "    df['WeekDay'] = df['InvoiceDate'].dt.dayofweek\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_valid_transactions(df):\n",
        "    \"\"\"Cria transações válidas com critérios mais flexíveis\"\"\"\n",
        "    print(\"Criando transações válidas...\")\n",
        "\n",
        "    # Critério mais flexível para tamanho das transações\n",
        "    transaction_sizes = df.groupby('InvoiceNo').size()\n",
        "    valid_size = transaction_sizes[\n",
        "        (transaction_sizes >= 2) &\n",
        "        (transaction_sizes <= transaction_sizes.quantile(0.975))\n",
        "    ].index\n",
        "\n",
        "    transactions = df[df['InvoiceNo'].isin(valid_size)].groupby('InvoiceNo')['Description'].agg(list)\n",
        "    return transactions.tolist()\n",
        "\n",
        "def generate_rules_by_period(df, min_support=0.02, min_confidence=0.4, max_lift=30):\n",
        "    \"\"\"Gera regras por período com parâmetros mais flexíveis\"\"\"\n",
        "    print(\"Gerando regras por período...\")\n",
        "\n",
        "    rules_by_month = {}\n",
        "\n",
        "    for month in df['Month'].unique():\n",
        "        month_data = df[df['Month'] == month]\n",
        "        month_transactions = create_valid_transactions(month_data)\n",
        "\n",
        "        te = TransactionEncoder()\n",
        "        te_ary = te.fit(month_transactions).transform(month_transactions)\n",
        "        df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "        frequent_itemsets = apriori(df_encoded,\n",
        "                                  min_support=min_support,\n",
        "                                  use_colnames=True)\n",
        "\n",
        "        if len(frequent_itemsets) > 0:\n",
        "            rules = association_rules(frequent_itemsets,\n",
        "                                    metric=\"confidence\",\n",
        "                                    min_threshold=min_confidence)\n",
        "\n",
        "            # Filtro mais flexível para lift\n",
        "            rules = rules[rules['lift'] <= max_lift]\n",
        "\n",
        "            # Adicionar mês para rastreamento\n",
        "            rules['month'] = month\n",
        "\n",
        "            rules_by_month[month] = rules\n",
        "            print(f\"Mês {month}: {len(rules)} regras encontradas\")\n",
        "\n",
        "    return rules_by_month\n",
        "\n",
        "def validate_rules(rules_by_month, min_periods=1):\n",
        "    \"\"\"Valida regras com critérios mais flexíveis\"\"\"\n",
        "    print(\"Validando regras...\")\n",
        "\n",
        "    all_rules = []\n",
        "\n",
        "    for month, rules in rules_by_month.items():\n",
        "        if len(rules) > 0:\n",
        "            all_rules.append(rules)\n",
        "\n",
        "    if len(all_rules) > 0:\n",
        "        validated_rules = pd.concat(all_rules)\n",
        "\n",
        "        # Agrupar regras similares\n",
        "        validated_rules['rule_key'] = validated_rules.apply(\n",
        "            lambda x: f\"{sorted(list(x['antecedents']))}→{sorted(list(x['consequents']))}\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Calcular métricas médias por regra\n",
        "        aggregated_rules = validated_rules.groupby('rule_key').agg({\n",
        "            'antecedents': 'first',\n",
        "            'consequents': 'first',\n",
        "            'support': 'mean',\n",
        "            'confidence': 'mean',\n",
        "            'lift': 'mean',\n",
        "            'month': 'count'  # Conta em quantos meses a regra aparece\n",
        "        }).reset_index()\n",
        "\n",
        "        # Ordenar por contagem de meses e depois por lift\n",
        "        aggregated_rules = aggregated_rules.sort_values(['month', 'lift'], ascending=[False, False])\n",
        "\n",
        "        return aggregated_rules\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def analyze_results(rules, df):\n",
        "    \"\"\"Análise mais detalhada dos resultados\"\"\"\n",
        "    print(\"\\n=== Análise das Regras ===\")\n",
        "\n",
        "    # Top regras por diferentes métricas\n",
        "    print(\"\\nTop 10 Regras por Confiança:\")\n",
        "    print(rules.nlargest(10, 'confidence')[\n",
        "        ['antecedents', 'consequents', 'confidence', 'lift', 'support', 'month']\n",
        "    ])\n",
        "\n",
        "    print(\"\\nTop 10 Regras por Lift:\")\n",
        "    print(rules.nlargest(10, 'lift')[\n",
        "        ['antecedents', 'consequents', 'confidence', 'lift', 'support', 'month']\n",
        "    ])\n",
        "\n",
        "    print(\"\\nTop 10 Regras mais Frequentes (por número de meses):\")\n",
        "    print(rules.nlargest(10, 'month')[\n",
        "        ['antecedents', 'consequents', 'confidence', 'lift', 'support', 'month']\n",
        "    ])\n",
        "\n",
        "    # Estatísticas das métricas\n",
        "    print(\"\\nEstatísticas das Métricas:\")\n",
        "    metrics_stats = rules[['support', 'confidence', 'lift', 'month']].describe()\n",
        "    print(metrics_stats)\n",
        "\n",
        "    # Análise de valor\n",
        "    print(\"\\nAnálise de Valor das Regras Mais Frequentes:\")\n",
        "    df_value = df.copy()\n",
        "    df_value['TotalValue'] = df_value['Quantity'] * df_value['UnitPrice']\n",
        "    value_by_product = df_value.groupby('Description')['TotalValue'].sum()\n",
        "\n",
        "    for _, rule in rules.nlargest(5, 'month').iterrows():\n",
        "        ant_products = list(rule['antecedents'])\n",
        "        cons_products = list(rule['consequents'])\n",
        "\n",
        "        try:\n",
        "            ant_value = sum(value_by_product[ant_products])\n",
        "            cons_value = sum(value_by_product[cons_products])\n",
        "\n",
        "            print(f\"\\nRegra (presente em {int(rule['month'])} meses):\")\n",
        "            print(f\"Antecedentes: {ant_products}\")\n",
        "            print(f\"Consequentes: {cons_products}\")\n",
        "            print(f\"Valor Total Antecedentes: £{ant_value:.2f}\")\n",
        "            print(f\"Valor Total Consequentes: £{cons_value:.2f}\")\n",
        "            print(f\"Confiança: {rule['confidence']:.2%}\")\n",
        "            print(f\"Lift: {rule['lift']:.2f}\")\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "def main():\n",
        "    # Parâmetros ajustados para encontrar mais regras\n",
        "    MIN_SUPPORT = 0.02     # Reduzido de 0.05 para 0.02\n",
        "    MIN_CONFIDENCE = 0.4   # Reduzido de 0.7 para 0.4\n",
        "    MAX_LIFT = 30         # Aumentado de 20 para 30\n",
        "    MIN_PERIODS = 1       # Reduzido de 2 para 1\n",
        "\n",
        "    url = \"https://raw.githubusercontent.com/klaytoncastro/idp-machinelearning/main/resources/online_retail.zip\"\n",
        "\n",
        "    df = load_and_preprocess_data(url)\n",
        "    rules_by_month = generate_rules_by_period(df, MIN_SUPPORT, MIN_CONFIDENCE, MAX_LIFT)\n",
        "    validated_rules = validate_rules(rules_by_month, MIN_PERIODS)\n",
        "\n",
        "    if len(validated_rules) > 0:\n",
        "        analyze_results(validated_rules, df)\n",
        "        validated_rules.to_csv('regras_validadas_ajustadas.csv', index=False)\n",
        "        print(\"\\nResultados salvos em 'regras_validadas_ajustadas.csv'\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma regra válida encontrada mesmo com parâmetros ajustados.\")\n",
        "        print(\"Considere reduzir ainda mais os parâmetros ou revisar os dados.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOm_IdFbRpeM",
        "outputId": "08df3310-5562-4db1-e00c-058484ddae4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando e pré-processando dados...\n",
            "Gerando regras por período...\n",
            "Criando transações válidas...\n",
            "Mês 12: 59 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 1: 193 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 2: 277 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 3: 231 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 4: 219 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 5: 565 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 6: 375 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 7: 1079 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 8: 2020 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 9: 255 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 10: 170 regras encontradas\n",
            "Criando transações válidas...\n",
            "Mês 11: 135 regras encontradas\n",
            "Validando regras...\n",
            "\n",
            "=== Análise das Regras ===\n",
            "\n",
            "Top 10 Regras por Confiança:\n",
            "                                            antecedents  \\\n",
            "3135  (REGENCY TEAPOT ROSES, REGENCY TEA PLATE ROSES...   \n",
            "3140  (REGENCY TEAPOT ROSES, REGENCY TEA PLATE GREEN...   \n",
            "3149  (REGENCY TEA PLATE PINK, REGENCY TEA PLATE ROS...   \n",
            "3216  (ROSES REGENCY TEACUP AND SAUCER, REGENCY TEA ...   \n",
            "3250  (REGENCY TEA PLATE PINK, ROSES REGENCY TEACUP ...   \n",
            "478   (JUMBO BAG TOYS, JUMBO STORAGE BAG SUKI, JUMBO...   \n",
            "1366  (LUNCH BAG WOODLAND, LUNCH BAG SPACEBOY DESIGN...   \n",
            "1214  (LUNCH BAG SPACEBOY DESIGN, LUNCH BAG VINTAGE ...   \n",
            "3070  (REGENCY MILK JUG PINK, REGENCY TEA PLATE ROSE...   \n",
            "3089   (REGENCY MILK JUG PINK, REGENCY TEA PLATE GREEN)   \n",
            "\n",
            "                              consequents  confidence       lift   support  \\\n",
            "3135              (REGENCY MILK JUG PINK)    1.000000  21.907692  0.020365   \n",
            "3140              (REGENCY MILK JUG PINK)    1.000000  21.907692  0.021067   \n",
            "3149            (REGENCY TEA PLATE GREEN)    1.000000  20.056338  0.020365   \n",
            "3216            (REGENCY TEA PLATE ROSES)    1.000000  16.558140  0.020365   \n",
            "3250            (REGENCY TEA PLATE ROSES)    1.000000  16.558140  0.020365   \n",
            "478   (JUMBO SHOPPER VINTAGE RED PAISLEY)    1.000000  13.825243  0.020365   \n",
            "1366                (LUNCH BAG CARS BLUE)    1.000000  10.250000  0.020035   \n",
            "1214              (LUNCH BAG SUKI DESIGN)    1.000000   9.487603  0.020906   \n",
            "3070               (REGENCY TEAPOT ROSES)    0.970588  18.933118  0.023174   \n",
            "3089           (REGENCY SUGAR BOWL GREEN)    0.969697  21.918230  0.022472   \n",
            "\n",
            "      month  \n",
            "3135      1  \n",
            "3140      1  \n",
            "3149      1  \n",
            "3216      1  \n",
            "3250      1  \n",
            "478       1  \n",
            "1366      1  \n",
            "1214      1  \n",
            "3070      1  \n",
            "3089      1  \n",
            "\n",
            "Top 10 Regras por Lift:\n",
            "                         antecedents                     consequents  \\\n",
            "153          (FELTCRAFT CUSHION OWL)      (FELTCRAFT CUSHION RABBIT)   \n",
            "155       (FELTCRAFT CUSHION RABBIT)         (FELTCRAFT CUSHION OWL)   \n",
            "87        (BLUE VINTAGE SPOT BEAKER)       (RED VINTAGE SPOT BEAKER)   \n",
            "3059       (RED VINTAGE SPOT BEAKER)      (BLUE VINTAGE SPOT BEAKER)   \n",
            "11       (POPPY'S PLAYHOUSE BEDROOM)  (POPPY'S PLAYHOUSE LIVINGROOM)   \n",
            "14    (POPPY'S PLAYHOUSE LIVINGROOM)     (POPPY'S PLAYHOUSE BEDROOM)   \n",
            "10       (POPPY'S PLAYHOUSE BEDROOM)     (POPPY'S PLAYHOUSE KITCHEN)   \n",
            "12       (POPPY'S PLAYHOUSE KITCHEN)     (POPPY'S PLAYHOUSE BEDROOM)   \n",
            "121        (CHILDS GARDEN FORK PINK)     (CHILDS GARDEN TROWEL PINK)   \n",
            "124      (CHILDS GARDEN TROWEL PINK)       (CHILDS GARDEN FORK PINK)   \n",
            "\n",
            "      confidence       lift   support  month  \n",
            "153     0.842105  29.829240  0.020075      1  \n",
            "155     0.711111  29.829240  0.020075      1  \n",
            "87      0.725000  28.524219  0.023034      1  \n",
            "3059    0.906250  28.524219  0.023034      1  \n",
            "11      0.741379  28.326285  0.021235      1  \n",
            "14      0.811321  28.326285  0.021235      1  \n",
            "10      0.757663  27.512093  0.021741      2  \n",
            "12      0.789583  27.512093  0.021741      2  \n",
            "121     0.925926  27.469136  0.023408      1  \n",
            "124     0.694444  27.469136  0.023408      1  \n",
            "\n",
            "Top 10 Regras mais Frequentes (por número de meses):\n",
            "                            antecedents                          consequents  \\\n",
            "188   (GREEN REGENCY TEACUP AND SAUCER)    (ROSES REGENCY TEACUP AND SAUCER)   \n",
            "3312  (ROSES REGENCY TEACUP AND SAUCER)    (GREEN REGENCY TEACUP AND SAUCER)   \n",
            "149              (DOLLY GIRL LUNCH BOX)                 (SPACEBOY LUNCH BOX)   \n",
            "3420               (SPACEBOY LUNCH BOX)               (DOLLY GIRL LUNCH BOX)   \n",
            "529           (JUMBO BAG PINK POLKADOT)            (JUMBO BAG RED RETROSPOT)   \n",
            "1350          (LUNCH BAG  BLACK SKULL.)            (LUNCH BAG RED RETROSPOT)   \n",
            "40         (ALARM CLOCK BAKELIKE GREEN)           (ALARM CLOCK BAKELIKE RED)   \n",
            "56          (ALARM CLOCK BAKELIKE PINK)           (ALARM CLOCK BAKELIKE RED)   \n",
            "3457       (WOODEN FRAME ANTIQUE WHITE)  (WOODEN PICTURE FRAME WHITE FINISH)   \n",
            "2958               (LUNCH BAG WOODLAND)          (LUNCH BAG SPACEBOY DESIGN)   \n",
            "\n",
            "      confidence       lift   support  month  \n",
            "188     0.761617  14.886542  0.037754     11  \n",
            "3312    0.691547  14.886542  0.037754     11  \n",
            "149     0.645760  14.620645  0.025998     11  \n",
            "3420    0.577974  14.620645  0.025998     11  \n",
            "529     0.654808   6.796878  0.041456     11  \n",
            "1350    0.498202   6.610810  0.032276     11  \n",
            "40      0.685930  12.771809  0.036909     10  \n",
            "56      0.656877  12.310536  0.025356     10  \n",
            "3457    0.559269  10.626087  0.031559     10  \n",
            "2958    0.498534   7.812590  0.027453     10  \n",
            "\n",
            "Estatísticas das Métricas:\n",
            "           support   confidence         lift        month\n",
            "count  3479.000000  3479.000000  3479.000000  3479.000000\n",
            "mean      0.023884     0.606311    10.485384     1.603334\n",
            "std       0.004400     0.141443     4.216373     1.290542\n",
            "min       0.020021     0.400000     2.462576     1.000000\n",
            "25%       0.020906     0.486535     7.508177     1.000000\n",
            "50%       0.022521     0.579368     9.734284     1.000000\n",
            "75%       0.025052     0.711111    12.499902     2.000000\n",
            "max       0.061890     1.000000    29.829240    11.000000\n",
            "\n",
            "Análise de Valor das Regras Mais Frequentes:\n",
            "\n",
            "Regra (presente em 11 meses):\n",
            "Antecedentes: ['GREEN REGENCY TEACUP AND SAUCER']\n",
            "Consequentes: ['ROSES REGENCY TEACUP AND SAUCER']\n",
            "Valor Total Antecedentes: £20623.10\n",
            "Valor Total Consequentes: £22776.37\n",
            "Confiança: 76.16%\n",
            "Lift: 14.89\n",
            "\n",
            "Regra (presente em 11 meses):\n",
            "Antecedentes: ['ROSES REGENCY TEACUP AND SAUCER']\n",
            "Consequentes: ['GREEN REGENCY TEACUP AND SAUCER']\n",
            "Valor Total Antecedentes: £22776.37\n",
            "Valor Total Consequentes: £20623.10\n",
            "Confiança: 69.15%\n",
            "Lift: 14.89\n",
            "\n",
            "Regra (presente em 11 meses):\n",
            "Antecedentes: ['DOLLY GIRL LUNCH BOX']\n",
            "Consequentes: ['SPACEBOY LUNCH BOX']\n",
            "Valor Total Antecedentes: £11075.14\n",
            "Valor Total Consequentes: £12540.47\n",
            "Confiança: 64.58%\n",
            "Lift: 14.62\n",
            "\n",
            "Regra (presente em 11 meses):\n",
            "Antecedentes: ['SPACEBOY LUNCH BOX']\n",
            "Consequentes: ['DOLLY GIRL LUNCH BOX']\n",
            "Valor Total Antecedentes: £12540.47\n",
            "Valor Total Consequentes: £11075.14\n",
            "Confiança: 57.80%\n",
            "Lift: 14.62\n",
            "\n",
            "Regra (presente em 11 meses):\n",
            "Antecedentes: ['JUMBO BAG PINK POLKADOT']\n",
            "Consequentes: ['JUMBO BAG RED RETROSPOT']\n",
            "Valor Total Antecedentes: £18730.69\n",
            "Valor Total Consequentes: £36625.80\n",
            "Confiança: 65.48%\n",
            "Lift: 6.80\n",
            "\n",
            "Resultados salvos em 'regras_validadas_ajustadas.csv'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}